---
title: "Paper Mills, Fake Journals und die Erosion des Vertrauens"
subtitle: "Teil 2 der Serie: Epistemische Disruption"
author: Jochen Leeder
date: 2026-01-26
created: 2026-01-26 12:30:00
modified: 2026-01-26 12:30:00
tags:
  - ki
  - wissenschaft
  - publishing
  - paper-mills
  - desci
  - peer-review
  - forschung
  - blog
status: publish
type: post
summary: LLMs haben das GeschÃ¤ftsmodell wissenschaftlicher BetrÃ¼ger revolutioniert. Die Produktion gefÃ¤lschter Wissenschaft ist skalierbar geworden. Wie reagieren Verlage â€“ und welche radikalen Alternativen entstehen?
categories:
  - Wissenschaft
  - Technologie
---

> [!abstract] Die Industrialisierung des Betrugs
> WÃ¤hrend KI im persÃ¶nlichen Bereich als Effizienzgewinn gefeiert wird, hat sie im Kontext der Wissenschaft eine IntegritÃ¤tskrise ausgelÃ¶st. Das Vertrauen in die wissenschaftliche Aufzeichnung erodiert â€“ mit weitreichenden Folgen.

## Die Skalierung der TÃ¤uschung

Das PhÃ¤nomen der "Paper Mills" â€“ Organisationen, die Autorschaften auf gefÃ¤lschten Studien verkaufen â€“ existierte bereits vor der generativen KI. Doch Large Language Models haben das GeschÃ¤ftsmodell dieser BetrÃ¼ger revolutioniert.

Vor 2023 mussten Paper Mills auf "Spinbots" zurÃ¼ckgreifen, die Texte umschrieben, um Plagiatssoftware zu tÃ¤uschen. Das fÃ¼hrte zu den berÃ¼chtigten "tortured phrases" â€“ gequÃ¤lte Phrasen, bei denen etablierte Begriffe durch bizarre Synonyme ersetzt wurden. "Counterfeit consciousness" statt "artificial intelligence". Solche AbsurditÃ¤ten waren relativ leicht zu erkennen.

LLMs hingegen generieren Texte, die grammatikalisch perfekt und stilistisch Ã¼berzeugend sind. Sie halluzinieren Daten, Referenzen und Experimente, die fÃ¼r einen menschlichen Leser auf den ersten Blick plausibel wirken.

> [!warning] Das AusmaÃŸ des Problems
> Der Verlag Sage musste 2025 Ã¼ber 1.500 Artikel aus dem Journal of Intelligent and Fuzzy Systems zurÃ¼ckziehen. Die Datenbank von Retraction Watch nÃ¤hert sich 55.000 EintrÃ¤gen. Das traditionelle Peer-Review-System ist der Flut nicht gewachsen.

## Hijacked Journals: Die unsichtbare Front

Eine weitere Dimension des Betrugs sind "Hijacked Journals". BetrÃ¼ger kopieren die Webseiten legitimer, oft kleinerer Journale und leiten Einreichungen â€“ und PublikationsgebÃ¼hren â€“ auf ihre eigenen Server um.

KI erleichtert das Erstellen dieser tÃ¤uschend echten Fassaden und das FÃ¼llen der Seiten mit pseudowissenschaftlichem "FÃ¼llmaterial". Das fÃ¼hrt zu einer Kontamination der wissenschaftlichen Datenbanken wie Scopus oder Web of Science. GefÃ¤lschte Artikel zitieren legitime Artikel und verzerren so Zitationsmetriken.

Das Perfide: Selbst wenn ein Forscher sorgfÃ¤ltig recherchiert, kann er unwissentlich auf gefÃ¤lschte Quellen stoÃŸen, die alle Ã¤uÃŸeren Merkmale seriÃ¶ser Wissenschaft tragen.

## Die Antwort der Verlage

Die groÃŸen Wissenschaftsverlage â€“ Elsevier, Springer Nature, Wiley â€“ haben mit verschÃ¤rften Richtlinien reagiert. Der Konsens ist klar:

**Keine KI als Autor:** Eine KI kann juristisch und ethisch keine Verantwortung fÃ¼r die IntegritÃ¤t einer Studie Ã¼bernehmen und darf niemals als Autor gelistet werden. Autoren mÃ¼ssen die Nutzung von KI transparent machen, oft in Form eines "AI Declaration Statement".

**Das Bild-Verbot:** Besonders strikt sind die Regeln fÃ¼r wissenschaftliche Abbildungen. Elsevier verbietet die Nutzung generativer KI zur Erstellung oder VerÃ¤nderung von Bildern fast vollstÃ¤ndig. Der Grund: Ein generiertes Bild eines Zellkulturschnitts enthÃ¤lt keine "Wahrheit", sondern eine statistische Wahrscheinlichkeit von Pixeln. Da wissenschaftliche Evidenz auf Beobachtung und nicht auf Generierung beruht, gelten synthetische Bilder als FÃ¤lschung.

**Peer Review im Kreuzfeuer:** Auch der Review-Prozess selbst ist betroffen. Einerseits nutzen Reviewer KI, um Manuskripte schneller zu scannen. Andererseits gibt es Berichte Ã¼ber Review-Texte, die offensichtlich komplett von ChatGPT generiert wurden â€“ erkennbar an Phrasen wie "As an AI language model...". Das untergrÃ¤bt das Vertrauen der Autoren in eine faire Bewertung.

## Radikale Alternativen: DeSci und Executable Papers

Angesichts der SchwÃ¤chen des traditionellen Systems gewinnen alternative Modelle an AttraktivitÃ¤t.

### Das Ende des PDF

Das PDF-Format ist ein Anachronismus â€“ eine digitale Simulation von Papier. Es ist "tot", schwer maschinell zu lesen und trennt die Behauptung (Text) vom Beweis (Daten/Code).

Plattformen wie DeSci Labs oder Curvenote propagieren das "Executable Paper". In diesem Format ist ein Artikel kein monolithischer Block, sondern ein Container aus modularen Komponenten. Leser kÃ¶nnen Grafiken nicht nur betrachten, sondern den zugrundeliegenden Code live im Browser ausfÃ¼hren, Parameter Ã¤ndern und die Robustheit der Ergebnisse prÃ¼fen.

Das erhÃ¶ht die HÃ¼rde fÃ¼r BetrÃ¼ger massiv: Wer Daten erfindet, kann oft keinen funktionierenden Code liefern, der diese Daten plausibel generiert.

### Dezentralisierte Wissenschaft (DeSci)

DeSci nutzt Web3-Technologien, um die Kontrolle Ã¼ber das wissenschaftliche Protokoll zu dezentralisieren:

- **Permanenz**: Anstatt auf Verlagsservern zu liegen, werden Forschungsobjekte im IPFS (InterPlanetary File System) gespeichert. Das garantiert UnverÃ¤nderlichkeit und Zensurresistenz.

- **IdentitÃ¤t**: Durch "Persistent Identifiers" wird jede Version eines Manuskripts eindeutig und dauerhaft referenzierbar. Das bekÃ¤mpft "Link Rot" (das Verschwinden von Quellen) und "Content Drift" (das nachtrÃ¤gliche Ã„ndern von Inhalten).

- **Incentivierung**: DeSci-Modelle experimentieren mit Token-basierten Belohnungen fÃ¼r Peer Review, um die unbezahlte Arbeit der Gutachter wertzuschÃ¤tzen.

## Was das fÃ¼r meine Arbeit bedeutet

Als Entwickler einer Wissensmanagement-App muss ich diese Entwicklung im Blick behalten. ZukÃ¼nftige Tools werden wahrscheinlich nicht mehr PDFs parsen, sondern direkt mit strukturierten, semantischen Forschungsobjekten interagieren.

Die Frage der Provenienz â€“ woher stammt eine Information? â€“ wird zum zentralen Designprinzip. Wenn meine App eine Zusammenfassung generiert, muss sie die Quelle transparent machen. Nicht als nettes Feature, sondern als ethische Notwendigkeit in einer Welt, in der die Grenze zwischen Wissen und Halluzination verschwimmt.

> [!tip] Die Chance in der Krise
> Die Vertrauenskrise kÃ¶nnte paradoxerweise zu besserer Wissenschaft fÃ¼hren. Executable Papers, offene Daten, dezentrale Verifizierung â€“ all das macht Forschung reproduzierbarer und transparenter. Die Technologie, die das Problem geschaffen hat, kÃ¶nnte auch Teil der LÃ¶sung sein.

---

## ğŸ”— Verwandte BeitrÃ¤ge

- [[Vom Zettelkasten zum KI-Agenten]]
- [[Wenn die KI das Denken Ã¼bernimmt]]
- [[Wir sollten Ã¼ber unser SelbstwertgefÃ¼hl nachdenken]]
